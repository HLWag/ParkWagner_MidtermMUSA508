---
title: "Predicting Home Price in Miami"
author: "David Seunglee Park and Hannah Wagner"
date: "10/15/2020"
output: 
  html_document:
    code_folding: hide
    theme: paper
    highlight: tango
    toc: true
    toc_float:
      collapsed: false
---
OUTLINE - Original
1. introduction
  - set up
2. Data wrangling
  - make table with all datasets
  - main data
  - supplement data: coastline, bars/restaurant, crime, park, and metro data
  - census data
3. Analysis of created features
  - table with engineered features
    - one scatterplot for nn variables
    - table of slopes 
    - select nn vars for each dataset
  - map of your dependent variable (sale price)
  - 3 maps of independent variables
    - bars density map
    - map of 1 or 2 census data (NEED)
4. Test for correlation
  - correlation table with numeric values (only include selected nn vars) (NEED)
  - correlation table with census variables
  - text on highlighted relationships 
4. Model Building
  - one example model
    - provide written interpretation
  - trimmed/altered from the initial model
  - stepwise function process
  - final model (describe why we added a few more vars that we created)
    - add stargazer table with all regs models to compare
5. Cross Validation/ Results
  - test for accuracy via MAE
      - table of mean absolute error and MAPE for a single test set
  - Generalizability
      - provide result of cross validation
      - Plot of predicted prices as a function of observed prices
      - Provide a map of your residuals for your test set. 
          - Moran’s I test
          - a plot of the spatial lag in errors. 
      - Provide a map of your predicted values for where ‘toPredict’ is both 0 and 1. (NEED)
      - Using the test set predictions, provide a map of MAPE by neighborhood and possibly elementary school
      - Provide a scatterplot plot of MAPE by neighborhood as a function of mean price by neighborhood. 

6. Discussion/Conclusion


OUTLINE - I did some rearranging of this to make it fit more closely with the deliverables specified in the instructions. thoughts?
1. Introduction
  - Intro text (What is the purpose of this project? Why should we care about it? What makes this a difficult exercise? What is your overall modeling strategy? Briefly summarize your results.)
  - set up code
2. Data 
  - Describe methods for gathering data and provide code (hidden): (table with all datasets, main data, supplement data: coastline, bars/restaurant, crime, park, and metro data, census data)
      - Table with engineered features 
      - Table of Summary Statistics with Variable Descriptions (sorted by category, use stargazer)
  - Correlation Discussion:
      - Text describing our process for testing for correlation: 
      - Correlation Matrix
            - correlation table with numeric values (only include selected nn vars) (NEED)
            - correlation table with census variables
            - text on highlighted relationships 
      - Correlation Scatterplots: 
            - one scatterplot for nn variables and description of what we can tell from it
            - table of slopes
            - 4 Home prices scatterplots for variables we used in the model
  - Sale Price Map
  - 3 maps of interesting variables (bars density map, map of 1 or 2 census variables)
  - Other maps
  
3. Methods
  - Gathering Data (brief description, code is provided in section above)
  - Creating Features (brief description, code is provided in section above)
  - Testing for correlation (brief description, code is provided in section above)
  - Building Models (brief description & code)
        - one example model
        - provide written interpretation
        - trimmed/altered from the initial model
        - stepwise function process
        - final model (describe why we added a few more vars that we created)
        - add stargazer table with all regs models to compare
  - Cross Validating (describe, code shown in results below?)
  
4. Results
    -Split the ‘toPredict’ == 0 into a separate training and test set.
    -Provide a polished table of your (training set) lm summary results (coefficients, R2 etc).
    -Provide a polished table of mean absolute error and MAPE for a single test set. Check out the “kable” function for markdown to create nice tables.
    -Provide the results of your cross-validation tests. This includes mean and standard deviation MAE. Do 100 folds and plot your cross-validation MAE as a histogram. Is your model generalizable to new data?
    -Plot predicted prices as a function of observed prices
    -Provide a map of your residuals for your test set. Include a Moran’s I test and a plot of the spatial lag in errors. 5
    -Provide a map of your predicted values for where ‘toPredict’ is both 0 and 1.
    -Using the test set predictions, provide a map of mean absolute percentage error (MAPE) by neighborhood. 
    -Provide a scatterplot plot of MAPE by neighborhood as a function of mean price by neighborhood. 
    -Using tidycensus, split your city in to two groups (perhaps by race or income) and test your model’s generalizability. Is your model generalizable?

5. Discussion

6. Conclusion

###QUESITON####
- we are not predicting expensive housings. what are the solutions for this?
- adding neighborhood makes our model worse? 

- altering zipcode information

- how to get slope of the scatter plots
- after applying neighborhood/school zone, should we test errors again?


# 1. Introduction

Zillow’s housing market predictions, known as Zestimates, are valued for their nationwide coverage and general accuracy. For example, the nationwide median error for off-market homes is 7.5% and for on-market homes is 1.9%^[Zillow. 2020. "Zestimate." https://www.zillow.com/zestimate/]. However, when considering a specific city or region, the accuracy of the Zestimates could be improved by including locally-specific data in the prediction process. This analysis aims to build an accurate and generalizable hedonic model that predicts home prices for Miami by deconstructing overall home price into the value of constituent parts. Accurate models lead to only small differences between the predicted and observed values, and generalizable models accurately predict on new data and with comparable accuracy across various groups. By working to improve the accuracy and generalizability of the predictive model, we are ultimately striving to create a more useful decision-making tool. Such a model may be useful for local governments as they assess property taxes, for example.

## Modeling Strategy

To predict housing prices in the Miami area, we train a model using home prices from recent sales. Our model includes “features,” which are variables that are used to predict outcomes (in this case, home price). We use a hedonic model, which breaks home price into components that explain the cost: physical characteristics (e.g., living area), public services and amenities (e.g., distance parks), and the spatial process of prices (e.g., prices for homes within neighborhoods cluster together). Our process uses data wrangling, exploratory analysis, feature engineering, feature selection, and model estimate and validation to produce a hedonic model that effectively predicts home prices for Miami and Miami Beach. Key challenges inherent to this process involve identifying and cleaning publicly available data for inclusion, investigating underlying spatial processes and trends, and selecting an effective set of features for inclusion in the model while avoiding choosing variables that are too closely correlated with each other. 

## Results
Our results show…
Summary of the features included in our final model.
MAPE of percent and dollar amount for the final model
Would we recommend using this?

## Setup Code
To begin the analysis, this section loads libraries and options, specifies styling options for maps and plots, creates quantile break functions and quantile styling, and loads color palettes. This section also creates the "nearest neighbor" function, which calculates the average nearest neighbor distance from each home to its k nearest objects of interest. This calculation is useful for creating features that describe the relative amount of an amenity around each home. For example, the nearest neighbor function can tell us the average distance from each home to the closest 1, 2, 3, 4, or 5 parks, bars, and crime events. In our exploratory analysis, we determine which nearest neighbor features are most appropriate for inclusion in the model.

**Loading Libraries and Options**

```{r setup, include=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
	echo = TRUE)

library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot)
library(jtools)
library(mapview)
library(ggstance)
library(broom.mixed)
library(osmdata)
library(geosphere)
library(tidycensus)

options(scipen=999)
options(tigris_class = "sf")
```

**Loading Themes for Map and Plots**

```{r Themes, message=FALSE, warning=FALSE}

mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 13,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "lightskyblue1", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}

palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}

q5 <- function(variable) {as.factor(ntile(variable, 5))}
```

**Specifying Nearest Neighbor Function**

```{r NN Function, message=FALSE, warning=FALSE}
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
  output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull()
  
  return(output)  
}
```

# 2. Data 
This analysis uses data from a variety of sources: we derived physical characteristics of each house from the underlying home data, gathered public services and amenities information from the Miami-Dade County Open Data Hub and OpenStreetMap, and incorporated population data from the U.S. Census Bureau’s 5-year American Community Survey.

## Data Gathering: Description & Code
We accessed data for the analysis via the Miami-Dade County Open Data Hub API and using the osmdata package to access OpenStreetMap variables of interest. Most of the data required manipulation and cleaning before being explored. This process included transformations in order to maximize the effectiveness of prediction for each variable. The code below presents the steps in the data gathering process. 

**Loading Basemap**

```{r Basemap, message=FALSE, warning=FALSE}
# Loading Miami base map from OSM Data
miami.base <- 
  st_read("https://opendata.arcgis.com/datasets/5ece0745e24b4617a49f2e098df8117f_0.geojson") %>%
  filter(NAME == "MIAMI BEACH" | NAME == "MIAMI") %>%
  st_union()

xmin = st_bbox(miami.base)[[1]]
ymin = st_bbox(miami.base)[[2]]
xmax = st_bbox(miami.base)[[3]]  
ymax = st_bbox(miami.base)[[4]]
```

**Loading Home Data (Provided) and Neighborhood Data**

```{r Load Data, message=FALSE, warning=FALSE, results=FALSE}
MiamiProperties<-
  st_read("C:/Users/wagne/Documents/GitHub/ParkWagner_MidtermMUSA508/studentsData.geojson")%>%
  #st_read("/Users/davidseungleepark/Library/Mobile Documents/com~apple~CloudDocs/Fall 2020/cpln592/ParkWagner_MidtermMUSA508/studentsData.geojson") %>%
  
  mutate(pool = ifelse(str_detect((XF1), "Pool") | str_detect((XF2), "Pool") | str_detect((XF3), "Pool"), "Pool", "No Pool")) %>% 
  mutate(singlefamily = ifelse(str_detect(Zoning, "SINGLE FAMILY"), "Yes", "No")) %>%
  mutate(Age = (2020 - EffectiveYearBuilt),0) %>%
  mutate(luxury=ifelse(str_detect((XF1), "Luxury") | str_detect((XF2), "Luxury") | str_detect((XF3), "Luxury"), "Yes", "No")) %>%
  mutate(elevator=ifelse(str_detect((XF1), "Elevator") | str_detect((XF2), "Elevator") | str_detect((XF3), "Elevator"), "Yes", "No")) %>%
  dplyr::select(-Land, -Year,-Bldg, -Total, -Assessed,  -saleDate, -saleType, -saleQual, -County.Senior, -County.LongTermSenior, -County.Other.Exempt, -Owner1, -Owner2, 
                -Mailing.Address, -Mailing.City, -Mailing.State, -Mailing.Zip, -Mailing.Country, -YearBuilt,
                -City.Senior, -City.LongTermSenior, -City.Other.Exempt, -Legal1, -Legal2, -Legal3, -Legal4, -Legal5, -Legal6, -XF1, -XF2, -XF3,
                -WVDB, -HEX, -GPAR, -County.2nd.HEX, -City.2nd.HEX, -MillCode, -Zoning, -Land.Use)

st_crs(MiamiProperties)

# Loading elementary school boundaries 
elementary.school.boundaries <- 
  st_read("https://opendata.arcgis.com/datasets/19f5d8dcd9714e6fbd9043ac7a50c6f6_0.geojson") %>%
  st_transform('ESRI:102658')

#Neighborhood Data
neighborhood<-
  st_read("https://opendata.arcgis.com/datasets/2f54a0cbd67046f2bd100fb735176e6c_0.geojson")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(LABEL)%>%
  rename(Neighborhood=LABEL)

muni_boundary<-
  st_read("https://opendata.arcgis.com/datasets/5ece0745e24b4617a49f2e098df8117f_0.geojson")%>%
  filter(NAME=="MIAMI BEACH")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(NAME)%>%
  rename(Neighborhood=NAME)

all_nhoods<-
  rbind(neighborhood,muni_boundary)

#Miami Beach Neighborhoods
MBAreas<-st_read("https://opendata.arcgis.com/datasets/a21e846f4e8e4d81ad3b75bc4f334516_0.geojson")%>%
  filter(FID>1)%>%
  filter(FID<130)%>%
  filter(LAND=="Y")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(FID)%>%
  rename(Neighborhood=FID)

miami.base_map<-
  miami.base%>%
  st_transform('ESRI:102658')

elem_map<-
  elementary.school.boundaries%>%
  st_crop(miami.base_map)%>%
  rename(elem_name=NAME)

all_nhoods_MB<-
  rbind(neighborhood,MBAreas)%>%
  st_crop(miami.base_map)
```

**Calculating Distance to Coastline; Caculating proximity to Bars, Pubs, and Restaurants; Sexual Offenses; Parks; and Public Transportation**

```{r Feature Engineering, message=FALSE, warning=FALSE, cache=TRUE}
## Calculate the distance to Coastline (this calculation has to be in WGS84)
Coastline<-opq(bbox = c(xmin, ymin, xmax, ymax)) %>% 
  add_osm_feature("natural", "coastline") %>%
  osmdata_sf()

### add to MiamiProperties and convert to miles
MiamiProperties <-
  MiamiProperties %>%
  mutate(CoastDist=(geosphere::dist2Line(p=st_coordinates(st_centroid(MiamiProperties)),
                                        line=st_coordinates(Coastline$osm_lines)[,1:2])*0.00062137)[,1])

##Convert Miami Data to Local Projection #st_transform('ESRI:102658')
MiamiProperties <-
  MiamiProperties%>%
  st_transform('ESRI:102658')

MiamiProperties<-
  MiamiProperties%>%
  mutate(milecoast=ifelse(CoastDist<1,"Yes","No"))%>%
  mutate(halfmilecoast=ifelse(CoastDist<0.5,"Yes","No"))

## Add Data on Bars, pubs, and restaurants
bars <- opq(bbox = c(xmin, ymin, xmax, ymax)) %>% 
  add_osm_feature(key = 'amenity', value = c("bar", "pub", "restaurant")) %>%
  osmdata_sf()

bars<-
  bars$osm_points%>%
  .[miami.base,]

bars<-
  bars%>%
  st_transform('ESRI:102658')
  
MiamiProperties<-
  MiamiProperties %>%
  mutate(
    bars_nn1= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),1),
    bars_nn2= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),2),
    bars_nn3= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),3),
    bars_nn4= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),4),
    bars_nn5= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),5))

MiamiProperties$bars_Buffer =
  st_buffer(MiamiProperties, 660) %>%
  aggregate(mutate(dplyr::select(bars), counter = 1),., sum) %>%
  pull(counter)

MiamiProperties<-
  MiamiProperties%>%
  mutate(bars_Buffer = replace_na(bars_Buffer, 0))

## Add data on crime- Sexual Offenders and Predators within Miami-Dade County point data 
miami.sexualoffenders <-  
  st_read("https://opendata.arcgis.com/datasets/f8759d722aeb4198bfe7c4ad780604d2_0.geojson") %>%
  filter(CITY == "MIAMI" | CITY == "MIAMI BEACH" | CITY == "Miami" | CITY == "Miami Beach") %>%
  st_transform('ESRI:102658')

MiamiProperties$sexualoffenders_Buffer =
  st_buffer(MiamiProperties, 660) %>%
  aggregate(mutate(dplyr::select(miami.sexualoffenders), counter = 1),., sum) %>%
  pull(counter)

MiamiProperties<-
  MiamiProperties%>%
  mutate(sexualoffenders_Buffer = replace_na(sexualoffenders_Buffer, 0))

MiamiProperties <-
  MiamiProperties %>% 
  mutate(
    crime_nn1= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),1),
    crime_nn2= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),2),
    crime_nn3= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),3),
    crime_nn4= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),4),
    crime_nn5= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),5))

## Add the data on Park Facilities
Parks<-st_read("https://opendata.arcgis.com/datasets/8c9528d3e1824db3b14ed53188a46291_0.geojson")%>%
st_transform('ESRI:102658')

MiamiProperties<-
  MiamiProperties %>% 
  mutate(
    parks_nn1= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),1),
    parks_nn2= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),2),
    parks_nn3= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),3),
    parks_nn4= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),4),
    parks_nn5= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),5))

MiamiProperties$parks.Buffer =
  st_buffer(MiamiProperties, 660) %>%
  aggregate(mutate(dplyr::select(Parks), counter = 1),., sum) %>%
  pull(counter)

MiamiProperties<-
  MiamiProperties%>%
  mutate(parks.Buffer = replace_na(parks.Buffer, 0))

#TOD or non-TOD; distance to transit stop?
metrorail_stop<-st_read("https://opendata.arcgis.com/datasets/ee3e2c45427e4c85b751d8ad57dd7b16_0.geojson")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(NAME)

metromover_stop<-st_read("https://opendata.arcgis.com/datasets/aec76104165c4e879b9b0203fa436dab_0.geojson")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(NAME)

metro_stops<-
  rbind(metromover_stop,metrorail_stop)

#Distance to metro_stop (Added a column for the distance to the nearest stop and a column for homes that are within 0.5 miles of a stop)
MiamiProperties<-
  MiamiProperties %>% 
  mutate(
    metro_nn1= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(metro_stops),1),
    Halfmile_metro=ifelse(metro_nn1<2640,"Halfmile_metro","Non_Halfmile_metro"))
                                                      
```

**Adding Neighborhood and Elementary School Names to Each Home**

```{r Neighborhood, message=FALSE, warning=FALSE}
#Add Elementary School Name to Each Property
elementary.school.clean<-
  elementary.school.boundaries%>%
  dplyr::select(NAME)%>%
  rename(elem_name=NAME)

MiamiProperties<-
  MiamiProperties%>%
  st_join(elementary.school.clean)

#Add neighborhood name to each property
MiamiProperties<-
  MiamiProperties%>%
  st_join(all_nhoods_MB)#updated to include more designations in MB (note these are numbers not names)

#Add variable for Miami or Miami Beach
MiamiProperties<-
  MiamiProperties%>%
  mutate(MiamiBeach=ifelse(Property.City=="Miami Beach","Yes","No"))
```

**Loading Census Data**

```{r Census data,message=FALSE, warning=FALSE, cache=TRUE}
## Load in census data
census_api_key("41e1c0d912341017fa6f36a5da061d3b23de335e", overwrite = TRUE)

selected_vars <- c("B02001_001E", # Estimate!!Total population by race -- ##let's double check that it's okay to use this as long as we justify it
                   "B02001_002E", # People describing themselves as "white alone"
                   "B02001_003E", # People describing themselves as "black" or "african-american" alone
                   "B15001_050E", # Females with bachelors degrees
                   "B15001_009E", # Males with bachelors degrees
                   "B19013_001E", # Median HH income
                   "B25058_001E", # Median rent
                   "B06012_002E", # Total poverty
                   "B08301_001E", # People who have means of transportation to work
                   "B08301_002E", # Total people who commute by car, truck, or van
                   "B08301_010E", # Total people who commute by public transportation"
                   "B03002_012E", # Estimate Total Hispanic or Latino by race
                   "B19326_001E", # Median income in past 12 months (inflation-adjusted)
                   "B07013_001E", # Total households
                   "B07013_002E", # Total owner-occupied households
                   "B07013_003E", # total renter-occupied households
                   "B25027_001E",
                   "B25027_010E",
                   "B25038_002E",
                   "B25038_003E",
                   "B25038_004E",
                   "B25038_005E",
                   "B19001_017E")

tracts18 <- 
  get_acs(geography = "tract", 
          variables = selected_vars, 
          year=2018, 
          state=12,
          county = 086,
          geometry=T, 
          output="wide") %>%
  st_transform('ESRI:102658') %>%
  rename(TotalPop = B02001_001E, 
         Whites = B02001_002E,
         Blacks = B02001_003E,
         FemaleBachelors = B15001_050E, 
         MaleBachelors = B15001_009E,
         MedHHInc = B19013_001E, 
         MedRent = B25058_001E,
         TotalPoverty = B06012_002E,
         TotalCommute = B08301_001E,
         CarCommute = B08301_002E,
         PubCommute = B08301_010E,
         TotalHispanic = B03002_012E,
         MedInc = B19326_001E,
         TotalHH = B07013_001E,
         OwnerHH = B07013_002E,
         RenterHH = B07013_003E,
         #TotalHH2 = B25027_001E,
         HHNoMort = B25027_010E,
         Own2017later = B25038_003E,
         Own201516 = B25038_004E,
         Own201014 = B25038_005E,
         HH200k = B19001_017E) %>%
  dplyr::select(-NAME, -starts_with("B0"), -starts_with("B1"), -starts_with("B2")) %>%
  mutate(pctWhite = (ifelse(TotalPop > 0, Whites / TotalPop,0))*100,
         pctBlack = (ifelse(TotalPop > 0, Blacks / TotalPop,0))*100,
         pctHis = (ifelse(TotalPop >0, TotalHispanic/TotalPop,0))*100,
         pctBlackorHis = (ifelse (TotalPop>0, (Blacks+TotalHispanic)/TotalPop,0)) *100,
         pctBachelors = (ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop),0)) *100,
         pctPoverty = (ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0))*100,
         pctCarCommute = (ifelse(TotalCommute > 0, CarCommute / TotalCommute,0))*100,
         pctPubCommute = (ifelse(TotalCommute > 0, PubCommute / TotalCommute,0))*100,
         pctOwnerHH = (ifelse(TotalHH > 0, OwnerHH / TotalHH,0))*100,
         pctRenterHH = (ifelse(TotalHH > 0, RenterHH / TotalHH,0))*100,
         pctNoMortgage = (ifelse(TotalHH > 0, HHNoMort / TotalHH,0))*100,
         pctOwnerSince2010 = (ifelse(OwnerHH > 0, ((Own2017later + Own201516 + Own201014) / OwnerHH),0)) *100,
         pctHH200kOrMore = (ifelse(TotalHH > 0, (HH200k/ TotalHH),0))*100,
         year = "2018") %>%
  mutate(MedHHInc = replace_na(MedHHInc, 0),
         MedRent = replace_na(MedRent,0)) %>%
  dplyr::select(-Whites, -Blacks, -FemaleBachelors, -MaleBachelors, -TotalPoverty, -CarCommute, -PubCommute, -TotalCommute, -TotalHispanic)

#merge the data into the MiamiProperties dataframe
MiamiProperties <-st_join(MiamiProperties,tracts18)
```

**Completing Feature Engineering and Filtering Out Homes Where Sales Prices Have Been Removed**

```{r remove toPredict, message=FALSE, warning=FALSE}
MiamiPropertiesAll<-MiamiProperties

#filter out the houses that we will need to predict
MiamiProperties<-
  MiamiProperties%>%
  filter(toPredict == 0)
```

### Variables:
Present a table of summary statistics with variable descriptions. Sort these variables by their category (internal characteristics, amenities/public services or spatial structure). Check out the `stargazer` package for this.

## Correlation:
As part of the exploratory analysis, we examined correlation to assist in identifying features that may be useful for predicting sales price. A correlation matrix helps us visualize correlation across numeric variables. In the figures, the darker colors imply stronger correlation. These plot helps to determine features that are correlated to sale prices (see sale prices row) and variables that are correlated with each other. Figure 1 depicts a correlation plot of variables derived from the U.S. Census Bureau. Figure 2 depicts the correlation between the numeric features included in the final model. We developed several correlation matrices with additional variables in order to help determine features to include in the final model.

```{r Correlation Matrix, message=FALSE, warning=FALSE}
#Correlation of Census Variables
censusVars <- 
  select(st_drop_geometry(MiamiProperties), SalePrice, MedHHInc, MedRent, pctWhite, pctBlack, pctHis, pctBlackorHis, 
          pctBachelors, pctPoverty, pctCarCommute, pctPubCommute, pctOwnerHH, pctRenterHH) %>% na.omit()
ggcorrplot(
  round(cor(censusVars), 1), 
  p.mat = cor_pmat(censusVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
  labs(title = "Correlation Across Census Variables",
       caption="Figure 1. Correlation Plot of Census Variables") 


#Correlation of Variables Included in Model
reg_final_vars <- 
  select(st_drop_geometry(MiamiProperties), SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, parks_nn1, MedHHInc, pctWhite, pctBachelors, 
         pctOwnerHH, pctCarCommute, pctOwnerSince2010, crime_nn5) %>% na.omit()

ggcorrplot(
  round(cor(reg_final_vars), 1), 
  p.mat = cor_pmat(reg_final_vars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
  labs(title = "Correlation Across Final Numeric Features",
       caption="Figure 2. Correlation Plot of All Numeric Features Included in Final Model") 
```

The charts below plot sales price as a function of numeric features. Figure 3 is an example of a diagnostic tool used to select features for inclusion in the final model. The series of plots show the relationship between sale price and 6 crime variables for sexual offender and predators within the region (5 nearest neighbor variables and one buffer variable that counts the number of offenses within 1/8 mile of each home). By reviewing the slopes of the plotted lines, we selected the crime variable that was most highly correlated with Sale Prices to include in the final model. 

Figure 4 depicts four correlation scatterplots between continuous features and sale prices that suggest correlation. In all cases, the regression line slopes upward from left to right, meaning that on average, as the variable of interest (e.g., home size, median household income, distance to the nearest park, and household income greater than $200,000) increases, so does price. Correlation can also be described by the slope of the line. The greater the slope, the greater the feature's effect on price.

```{r Correlation scatterplots, message=FALSE, warning=FALSE}
#Correlation Scatterplots for all NN variable for Crime, as an example:
st_drop_geometry(MiamiProperties) %>% 
  dplyr::select(SalePrice, crime_nn1, crime_nn2, crime_nn3, crime_nn4, crime_nn5, sexualoffenders_Buffer) %>%
  gather(Variable, Value, -SalePrice) %>% 
  ggplot(aes(Value, SalePrice)) +
  geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
  facet_wrap(~Variable, ncol = 3, scales = "free") +
  labs(title = "Correlation between Sale Price and Crime Features",
       caption="Figure 3. Correlation Scatterplot Depicting the Relationship Between Sale Price and Crime Features") +
  plotTheme()


#Correlation Scatterplots for Variables of Interest
st_drop_geometry(MiamiProperties) %>% 
  mutate(Age = 2020 - EffectiveYearBuilt) %>%
  dplyr::select(SalePrice, LivingSqFt, parks_nn1, MedHHInc, pctHH200kOrMore) %>%
  #filter(SalePrice <= 1000000, Age < 500) %>%
  gather(Variable, Value, -SalePrice) %>% 
  ggplot(aes(Value, SalePrice)) +
  geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
  facet_wrap(~Variable, ncol = 3, scales = "free") +
  labs(title = "Price as a Function of Continuous Variables",
       caption="Figure 4. Correlation between Selected Continuous Variables and Sale Price") +
  plotTheme()
```

Some of the features included in the analysis are categorical rather than numeric (see Figure 5). Instead of using slope to calculate correlation, we evaluate the difference in mean price across each category. Differences in mean sales prices across categories suggest that the variable may be a good predictor of Sale Prices. 

```{r Categorical variable charts, message=FALSE, warning=FALSE}
st_drop_geometry(MiamiProperties) %>%
  dplyr::select(SalePrice, Halfmile_metro, Stories, pool, singlefamily, elevator, luxury)%>%
  gather(Variable,Value, -SalePrice)%>%
  ggplot(aes(Value, SalePrice))+
  geom_bar(position="dodge",stat="summary", fun.y="mean")+
  facet_wrap(~Variable, ncol=1, scales="free")+
  labs(title = "Price as a Function of Categorical Variables",
       caption="Figure 5. Correlation between Selected Categorical Variables and Average Sale Price") +
  plotTheme()
```

Figure 6 depicts the spatial distribution of sale prices (or price per square foot) across Miami and Miami Beach. The map suggests that prices are clustered within the city, rather than randomly distributed. In other words, homes with a greater price per square foot (orange color) are grouped together (e.g., on the eastern coast of the mainland and within Miami Beach) and homes with a lower price per square foot (green color) are grouped together father inland.

```{r Sale price map, message=FALSE, warning=FALSE}
Miami.Plot<-
  MiamiProperties%>%
  mutate(PricePerSq=SalePrice/ActualSqFt)

ggplot()+
  geom_sf(data=all_nhoods_MB, fill="grey40")+
  geom_sf(data=Miami.Plot, aes(colour=q5(PricePerSq)),
          show.legend="point", size=.75)+
  scale_colour_manual(values=palette5,
                      labels=qBr(Miami.Plot, "PricePerSq"),
                      name="Quintile\nBreaks")+
  labs(title="Price Per Square Foot, Miami",
       caption="Figure 6. Price per Square Foot for Homes in Miami and Miami Beach") +
  mapTheme()
```

The maps below depict independent variables included in the final model. Figure 7 depicts the density of sexual offenders and predators in Miami and Miami Beach. The locations with the greatest density of sexual offenders and predators in the norther portions of Miami. Figure 8 shows the locations of County

```{r independent variable maps, message=FALSE, warning=FALSE}
#density of sexual offenders
sexual_offend_map<-
  miami.sexualoffenders%>%
  st_intersection(all_nhoods)

ggplot() + geom_sf(data = all_nhoods_MB, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(sexual_offend_map)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Locations of Sexual Offenders and Predators",
       caption="Figure 7. Density of Sexual Offenders in Miami and Miami Beach") +
  mapTheme()

#Parks
Parks_map<-
  Parks%>%
  st_intersection(all_nhoods_MB)
ggplot()+
  geom_sf(data=all_nhoods_MB, fill="grey40")+
  geom_sf(data=Parks_map, size=1, color="lightgreen")+
  labs(title="Park Locations",
       catption="Figure 8. Locations of Park Facilities in Miami and Miami Beach") +
  mapTheme()


#Single Family Homes vs. Multi Family Homes
ggplot()+
  geom_sf(data=all_nhoods_MB, fill="grey40")+
  geom_sf(data=Miami.Plot, aes(colour=singlefamily),
          show.legend="point", size=.75)+
  labs(title="Single vs. Multi Family Homes",
       caption="Figure 9. Single and Multi Family Homes in Miami and Miami Beach") +
  mapTheme()

```

# 3. Methods

  - Gathering Data (brief description, code is provided in section above)
  - Creating Features (brief description, code is provided in section above)
  - Testing for correlation (brief description, code is provided in section above)
  - Building Models (brief description & code)
        - one example model
        - provide written interpretation
        - trimmed/altered from the initial model
        - stepwise function process
        - final model (describe why we added a few more vars that we created)
        - add stargazer table with all regs models to compare
  - Cross Validating (describe, code shown in results below?)

## Model Building

# 4. Model Building
```{r}
reg1 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
                  dplyr::select(SalePrice, LotSize, Bed, Bath, Age, 
                                ActualSqFt, parks_nn1, MedRent, MedHHInc, pctWhite, pctBlack, pctHis, pctBlackorHis, pctBachelors, pool, 
                                singlefamily, pctOwnerHH, pctRenterHH, crime_nn5, milecoast, pctNoMortgage, pctOwnerSince2010, pctCarCommute, pctPubCommute, 
                                pctPoverty, Halfmile_metro, metro_nn1, sexualoffenders_Buffer, milecoast, CoastDist, pctHH200kOrMore))
summary(reg_initial)
## trimmed/ cleaned up model from the inital model

##stepwise backward function
step( lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
           dplyr::select(SalePrice, LotSize, Bed, Bath, Age, 
                         ActualSqFt, parks_nn1, MedRent, MedHHInc, pctWhite, pctBlack, pctHis, pctBlackorHis, pctBachelors, pool, 
                         singlefamily, pctOwnerHH, pctRenterHH, crime_nn5, milecoast, pctNoMortgage, pctOwnerSince2010, pctCarCommute, pctPubCommute, 
                         pctPoverty, Halfmile_metro, metro_nn1, sexualoffenders_Buffer, milecoast, CoastDist,pctHH200kOrMore)), direction="backward")
##output
reg3 <- step( lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
                           dplyr::select(SalePrice, LotSize, Bed, Bath, Age, 
                                         ActualSqFt, parks_nn1, MedRent, MedHHInc, pctWhite, pctBlack, pctHis, pctBlackorHis, pctBachelors, pool, 
                                         singlefamily, pctOwnerHH, pctRenterHH, crime_nn5, milecoast, pctNoMortgage, pctOwnerSince2010, pctCarCommute, pctPubCommute, 
                                         pctPoverty, Halfmile_metro, metro_nn1, sexualoffenders_Buffer, milecoast, pctHH200kOrMore)), direction="backward")
summary(reg3)

#crime_nn5
reg4 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
                    dplyr::select(SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, parks_nn1, MedRent, MedHHInc, pctBlackorHis, pctBachelors, pool, 
                                  singlefamily, pctOwnerHH, pctCarCommute, pctHH200kOrMore, Halfmile_metro, crime_nn5))
summary(reg4)
#crime buffer
reg5 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
             dplyr::select(SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, parks_nn1, MedRent, MedHHInc, pctBlackorHis, pctBachelors, pool, 
                            singlefamily, pctOwnerHH, pctCarCommute, pctHH200kOrMore, Halfmile_metro, sexualoffenders_Buffer))
summary(reg5)


stargazer(reg1, reg3, reg4, reg5, type = "latex")
```

## Cross Validation

# 6. Predicitons
