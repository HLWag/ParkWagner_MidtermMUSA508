---
title: "Predicting Home Price in Miami"
author: "David Seunglee Park and Hannah Wagner"
date: "10/15/2020"
output: 
  html_document:
    code_folding: hide
    theme: paper
    highlight: tango
    toc: true
    toc_float:
      collapsed: false
---
OUTLINE - Original
1. introduction
  - set up
2. Data wrangling
  - make table with all datasets
  - main data
  - supplement data: coastline, bars/restaurant, crime, park, and metro data
  - census data
3. Analysis of created features
  - table with engineered features
    - one scatterplot for nn variables
    - table of slopes 
    - select nn vars for each dataset
  - map of your dependent variable (sale price)
  - 3 maps of independent variables
    - bars density map
    - map of 1 or 2 census data (NEED)
4. Test for correlation
  - correlation table with numeric values (only include selected nn vars) (NEED)
  - correlation table with census variables
  - text on highlighted relationships 
4. Model Building
  - one example model
    - provide written interpretation
  - trimmed/altered from the initial model
  - stepwise function process
  - final model (describe why we added a few more vars that we created)
    - add stargazer table with all regs models to compare
5. Cross Validation/ Results
  - test for accuracy via MAE
      - table of mean absolute error and MAPE for a single test set
  - Generalizability
      - provide result of cross validation
      - Plot of predicted prices as a function of observed prices
      - Provide a map of your residuals for your test set. 
          - Moran’s I test
          - a plot of the spatial lag in errors. 
      - Provide a map of your predicted values for where ‘toPredict’ is both 0 and 1. (NEED)
      - Using the test set predictions, provide a map of MAPE by neighborhood and possibly elementary school
      - Provide a scatterplot plot of MAPE by neighborhood as a function of mean price by neighborhood. 

6. Discussion/Conclusion


OUTLINE - I did some rearranging of this to make it fit more closely with the deliverables specified in the instructions. thoughts?
1. Introduction
  - Intro text (What is the purpose of this project? Why should we care about it? What makes this a difficult exercise? What is your overall modeling strategy? Briefly summarize your results.)
  - set up code
2. Data 
  - Describe methods for gathering data and provide code (hidden): (table with all datasets, main data, supplement data: coastline, bars/restaurant, crime, park, and metro data, census data)
      - Table with engineered features 
      - Table of Summary Statistics with Variable Descriptions (sorted by category, use stargazer)
  - Correlation Discussion:
      - Text describing our process for testing for correlation: 
      - Correlation Matrix
            - correlation table with numeric values (only include selected nn vars) (NEED)
            - correlation table with census variables
            - text on highlighted relationships 
      - Correlation Scatterplots: 
            - one scatterplot for nn variables and description of what we can tell from it
            - table of slopes
            - 4 Home prices scatterplots for variables we used in the model
  - Sale Price Map
  - 3 maps of interesting variables (bars density map, map of 1 or 2 census variables)
  - Other maps
  
3. Methods
  - Gathering Data (brief description, code is provided in section above)
  - Creating Features (brief description, code is provided in section above)
  - Testing for correlation (brief description, code is provided in section above)
  - Building Models (brief description & code)
        - one example model
        - provide written interpretation
        - trimmed/altered from the initial model
        - stepwise function process
        - final model (describe why we added a few more vars that we created)
        - add stargazer table with all regs models to compare
  - Cross Validating (describe, code shown in results below?)
  
4. Results
    -Split the ‘toPredict’ == 0 into a separate training and test set.
    -Provide a polished table of your (training set) lm summary results (coefficients, R2 etc).
    -Provide a polished table of mean absolute error and MAPE for a single test set. Check out the “kable” function for markdown to create nice tables.
    -Provide the results of your cross-validation tests. This includes mean and standard deviation MAE. Do 100 folds and plot your cross-validation MAE as a histogram. Is your model generalizable to new data?
    -Plot predicted prices as a function of observed prices
    -Provide a map of your residuals for your test set. Include a Moran’s I test and a plot of the spatial lag in errors. 5
    -Provide a map of your predicted values for where ‘toPredict’ is both 0 and 1.
    -Using the test set predictions, provide a map of mean absolute percentage error (MAPE) by neighborhood. 
    -Provide a scatterplot plot of MAPE by neighborhood as a function of mean price by neighborhood. 
    -Using tidycensus, split your city in to two groups (perhaps by race or income) and test your model’s generalizability. Is your model generalizable?

5. Discussion

6. Conclusion

###QUESITON####
- we are not predicting expensive housings. what are the solutions for this?
- adding neighborhood makes our model worse? 

- altering zipcode information

- how to get slope of the scatter plots
- after applying neighborhood/school zone, should we test errors again?

```{r initial, include=FALSE, message=FALSE, warning=FALSE}

library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot)
library(jtools)
library(mapview)
library(ggstance)
library(broom.mixed)
library(osmdata)
library(geosphere)
library(tidycensus)
library(stargazer)
library(kableExtra)

options(scipen=999)
options(tigris_class = "sf")
```

# 1. Introduction

Zillow’s housing market predictions, known as Zestimates, are valued for their nationwide coverage and general accuracy. For example, the nationwide median error for off-market homes is 7.5% and for on-market homes is 1.9%^[Zillow. 2020. "Zestimate." https://www.zillow.com/zestimate/]. However, when considering a specific city or region, the accuracy of the Zestimates could be improved by including locally-specific data in the prediction process. This analysis aims to build an accurate and generalizable hedonic model that predicts home prices for Miami by deconstructing overall home price into the value of constituent parts. Accurate models lead to only small differences between the predicted and observed values, and generalizable models accurately predict on new data and with comparable accuracy across various groups. By working to improve the accuracy and generalizability of the predictive model, we are ultimately striving to create a more useful decision-making tool. Such a model may be useful for local governments as they assess property taxes, for example.

## Modeling Strategy

To predict housing prices in the Miami area, we train a model using home prices from recent sales. Our model includes “features,” which are variables that are used to predict outcomes (in this case, home price). We use a hedonic model, which breaks home price into components that explain the cost: physical characteristics (e.g., living area), public services and amenities (e.g., distance to parks), and the spatial process of prices (e.g., prices for homes within neighborhoods cluster together). Our process uses data wrangling, exploratory analysis, feature engineering, feature selection, and model estimate and validation to produce a hedonic model that effectively predicts home prices for Miami and Miami Beach. Key challenges inherent to this process involve identifying and cleaning publicly available data for inclusion, investigating underlying spatial processes and trends, and selecting an effective set of features for inclusion in the model while avoiding choosing variables that are too closely correlated with each other. 

## Results
Our final model for predicting home prices includes the 20 independent variables shown in Table 1. MAPE of percent and dollar amount for the final model. Would we recommend using this? Some text about how this model performs when we remove homes over 1 million.

```{r variables, message=FALSE, warning=FALSE}
finalvars<- c('Lot Size', 'Number of Bedrooms', 'Number of Bathrooms', 'Home Age', 'Home Size', 'Presence of a Pool', 'Whether the Property is a Single Family Home', 'Presence of Luxury Features', 'Presence of an Elevator', 'Presence of a Dock', 'Estate Zoning', 'Number of Sexual Offenders or Predators within an Eighth Mile of the Home', 'Distance to the Nearest Park', 'Within 0.5 miles of a Metro Stop', 'Median Household Income', 'Percent of Population that is Hispanic', 'Percent of Population with a Bachelors Degree', 'Percent of Households that are Owned', 'Percent of Population that Commutes via Car', 'Percent of Households with a Household Income of $200,000 or more')

vartype<-c('Internal Characteristic', 'Internal Characteristic','Internal Characteristic','Internal Characteristic','Internal Characteristic','Internal Characteristic','Internal Characteristic','Internal Characteristic','Internal Characteristic','Internal Characteristic','Internal Characteristic', 'Amenities/Public Services', 'Amenities/Public Services', 'Amenities/Public Services', 'Spatial Structure', 'Spatial Structure', 'Spatial Structure', 'Spatial Structure', 'Spatial Structure', 'Spatial Structure')

datasource<-c('Home Data', 'Home Data', 'Home Data', 'Home Data', 'Home Data', 'Home Data', 'Home Data', 'Home Data', 'Home Data', 'Home Data', 'Home Data', 'Miami Dade County Open Data', 'OpenStreetMap', 'Miami Dade County Open Data', 'U.S. Census Bureau American Community Survey', 'U.S. Census Bureau American Community Survey', 'U.S. Census Bureau American Community Survey', 'U.S. Census Bureau American Community Survey', 'U.S. Census Bureau American Community Survey', 'U.S. Census Bureau American Community Survey')

varsdesc<- c(
  'Total Lot Size in Square Feet',
  'Total Number of Bedrooms in the Home',
  'Total Number of Bathrooms in the Home',
  'Age of the Home, as of 2020',
  'Total Size of the Home in Square Feet',
  'Whether or Not the Property Includes a Pool',
  'Whether the Property is a Single-Family Home or a Multi-Family Home',
  'Whether the Home Contains any Luxury Features',
  'Whether the Home Contains an Elevator',
  'Whether the Home Contains a Dock',
  'Whether the Home is Zoned as an Estate',
  'The Number of Sexual Offenders and Predators within an Eighth of a Mile of the Home',
  'Distance (in feet) to the nearest Park',
  'Whether the Home is Within a Half-Mile of a MetroMover or MetroRail Stop',
  'Median Household Income in the Census Tract',
  'Percent of Population in the Census Tract that is Hispanic',
  'Percent of Population in the Census Tract with a Bachelors Degree',
  'Percent of Households in the Census Tract that are Owned',
  'Percent of Population in the Census Tract that Commutes via Car',
  'Percent of Households in the Census Tract with a Household Income of $200,000 or more')

varstable<- data.frame(finalvars, datasource, varsdesc)

varstable%>%
  rename(Final_Variables = finalvars,
         #Variable_Type = vartype,
         Data_Source = datasource,
         Variable_Description = varsdesc)%>%
  kable(caption="Table 1. Final Independent Variables Included in Home Price Prediction Model")%>%
  pack_rows("Internal Characteristic", 1, 11, label_row_css = "background-color: #25CB10") %>%
  pack_rows("Amenities/Public Services", 12,14, label_row_css = "background-color: #faf500")%>%
  pack_rows("Spatial Structure", 15, 20, label_row_css = "background-color: #FA7800")%>%
  kable_styling("striped", full_width = F)%>%
  scroll_box(height = "250px")
  
```


## Setup Code
To begin the analysis, this section loads libraries and options, specifies styling options for maps and plots, creates quantile break functions and quantile styling, and loads color palettes. This section also creates the "nearest neighbor" function, which calculates the average nearest neighbor distance from each home to its k nearest objects of interest. This calculation is useful for creating features that describe the relative amount of an amenity around each home. For example, the nearest neighbor function can tell us the average distance from each home to the closest 1, 2, 3, 4, or 5 parks, bars, and crime events. In our exploratory analysis, we determine which nearest neighbor features are most appropriate for inclusion in the model.

**Loading Libraries and Options**

```{r setup, include=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
	echo = TRUE)

library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot)
library(jtools)
library(mapview)
library(ggstance)
library(broom.mixed)
library(osmdata)
library(geosphere)
library(tidycensus)
library(stargazer)
library(kableExtra)
library(kableExtra)
library(stargazer)

options(scipen=999)
options(tigris_class = "sf")
```

**Loading Themes for Map and Plots**

```{r Themes, message=FALSE, warning=FALSE}

mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 13,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "lightskyblue1", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}

palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}

q5 <- function(variable) {as.factor(ntile(variable, 5))}
```

**Specifying Nearest Neighbor Function**

```{r NN Function, message=FALSE, warning=FALSE}
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
  output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull()
  
  return(output)  
}
```

# 2. Data 
This analysis uses data from a variety of sources: we derived physical characteristics of each house from the underlying home data, gathered public services and amenities information from the Miami-Dade County Open Data Hub and OpenStreetMap, and incorporated population data from the U.S. Census Bureau’s 5-year American Community Survey.

## Data Gathering: Description & Code
We accessed data for the analysis via the Miami-Dade County Open Data Hub API and using the osmdata package to access OpenStreetMap variables of interest. Most of the data required manipulation and cleaning before being explored. This process included transformations in order to maximize the effectiveness of prediction for each variable. The code below presents the steps in the data gathering process. 

```{r}
text_tabl <-data.frame(
  Datasets = c("Miami Home Dataset", "Coastline Data", "Bars, Pubs, & Restaurant Data", "Sexual Offenders Data", "Miami Park Facilities Data","Miami-Dade Transit (MDT) Metromover and Metrorail stations", "2014-2018 ACS 5-year Estimates"),
  Source = c("Provided", "OpenStreetMap", "OpenStreetMap", "Miami-Dade County Open Data Hub", "Miami-Dade County Open Data Hub", "Miami-Dade County Open Data Hub", "U.S. Census Bureau")
)

kbl(text_tabl) %>%
  kable_paper(c("hover", "condensed"), full_width = F, html_font = "Montserrat") %>%
  kable_styling (bootstrap_options = "striped", "condensed", font_size = 10) %>%
  row_spec(0, bold = T, color = "white", background = "dodgerblue", font_size = 14)
```

**Loading Basemap**

```{r Basemap, message=FALSE, warning=FALSE, results='hide'}
# Loading Miami base map from OSM Data
miami.base <- 
  st_read("https://opendata.arcgis.com/datasets/5ece0745e24b4617a49f2e098df8117f_0.geojson") %>%
  filter(NAME == "MIAMI BEACH" | NAME == "MIAMI") %>%
  st_union()

xmin = st_bbox(miami.base)[[1]]
ymin = st_bbox(miami.base)[[2]]
xmax = st_bbox(miami.base)[[3]]  
ymax = st_bbox(miami.base)[[4]]
```

**Loading Home Data (Provided) and Neighborhood Data**

```{r Load Data, message=FALSE, warning=FALSE, results=FALSE, results='hide'}
MiamiProperties<-
  #st_read("C:/Users/wagne/Documents/GitHub/ParkWagner_MidtermMUSA508/studentsData.geojson")%>%
  st_read("/Users/davidseungleepark/Library/Mobile Documents/com~apple~CloudDocs/Fall 2020/cpln592/ParkWagner_MidtermMUSA508/studentsData.geojson") %>%
  
  mutate(pool = ifelse(str_detect((XF1), "Pool") | str_detect((XF2), "Pool") | str_detect((XF3), "Pool"), "Pool", "No Pool")) %>% 
  mutate(singlefamily = ifelse(str_detect(Zoning, "SINGLE FAMILY"), "Yes", "No")) %>%
  mutate(estates = ifelse(str_detect(Zoning, "ESTATES"), "Yes", "No")) %>%
  mutate(dock = ifelse(str_detect((XF1), "Dock") | str_detect((XF2), "Dock") | str_detect((XF3), "Dock"), "Dock", "No Dock")) %>%
  mutate(Age = (2020 - EffectiveYearBuilt),0) %>%
  mutate(luxury=ifelse(str_detect((XF1), "Luxury") | str_detect((XF2), "Luxury") | str_detect((XF3), "Luxury"), "Yes", "No")) %>%
  mutate(elevator=ifelse(str_detect((XF1), "Elevator") | str_detect((XF2), "Elevator") | str_detect((XF3), "Elevator"), "Yes", "No")) %>%
  mutate(Gazebo=ifelse(str_detect((XF1), "Gazebo") | str_detect((XF2), "Gazebo") | str_detect((XF3), "Gazebo"), "Yes", "No")) %>%
  mutate(BeachView=ifelse(str_detect((Legal1), "BEACH VIEW") | str_detect((Legal2), "BEACH VIEW") | str_detect((Legal3), "BEACH VIEW"), "Yes", "No")) %>%
  dplyr::select(-Land, -Year,-Bldg, -Total, -Assessed,  -saleDate, -saleType, -saleQual, -County.Senior, -County.LongTermSenior, -County.Other.Exempt, -Owner1, -Owner2, 
                -Mailing.Address, -Mailing.City, -Mailing.State, -Mailing.Zip, -Mailing.Country, -YearBuilt,
                -City.Senior, -City.LongTermSenior, -City.Other.Exempt, -Legal1, -Legal2, -Legal3, -Legal4, -Legal5, -Legal6, -XF1, -XF2, -XF3,
                -WVDB, -HEX, -GPAR, -County.2nd.HEX, -City.2nd.HEX, -MillCode, -Zoning, -Land.Use)

st_crs(MiamiProperties)

# Loading elementary school boundaries 
elementary.school.boundaries <- 
  st_read("https://opendata.arcgis.com/datasets/19f5d8dcd9714e6fbd9043ac7a50c6f6_0.geojson") %>%
  st_transform('ESRI:102658')

#Neighborhood Data
neighborhood<-
  st_read("https://opendata.arcgis.com/datasets/2f54a0cbd67046f2bd100fb735176e6c_0.geojson")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(LABEL)%>%
  rename(Neighborhood=LABEL)

muni_boundary<-
  st_read("https://opendata.arcgis.com/datasets/5ece0745e24b4617a49f2e098df8117f_0.geojson")%>%
  filter(NAME=="MIAMI BEACH")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(NAME)%>%
  rename(Neighborhood=NAME)

all_nhoods<-
  rbind(neighborhood,muni_boundary)

#Miami Beach Neighborhoods
MBAreas<-st_read("https://opendata.arcgis.com/datasets/a21e846f4e8e4d81ad3b75bc4f334516_0.geojson")%>%
  filter(FID>1)%>%
  filter(FID<130)%>%
  filter(LAND=="Y")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(FID)%>%
  rename(Neighborhood=FID)

miami.base_map<-
  miami.base%>%
  st_transform('ESRI:102658')

elem_map<-
  elementary.school.boundaries%>%
  st_crop(miami.base_map)%>%
  rename(elem_name=NAME)

all_nhoods_MB<-
  rbind(neighborhood,MBAreas)%>%
  st_crop(miami.base_map)
```

**Calculating Distance to Coastline; Calculating proximity to Bars, Pubs, and Restaurants; Sexual Offenses; Parks; and Public Transportation**

```{r Feature Engineering, message=FALSE, warning=FALSE, cache=TRUE, results='hide'}
## Calculate the distance to Coastline (this calculation has to be in WGS84)
Coastline<-opq(bbox = c(xmin, ymin, xmax, ymax)) %>% 
  add_osm_feature("natural", "coastline") %>%
  osmdata_sf()

### add to MiamiProperties and convert to miles
MiamiProperties <-
  MiamiProperties %>%
  mutate(CoastDist=(geosphere::dist2Line(p=st_coordinates(st_centroid(MiamiProperties)),
                                        line=st_coordinates(Coastline$osm_lines)[,1:2])*0.00062137)[,1])

##Convert Miami Data to Local Projection #st_transform('ESRI:102658')
MiamiProperties <-
  MiamiProperties%>%
  st_transform('ESRI:102658')

MiamiProperties<-
  MiamiProperties%>%
  mutate(milecoast=ifelse(CoastDist<1,"Yes","No"))%>%
  mutate(halfmilecoast=ifelse(CoastDist<0.5,"Yes","No"))

## Add Data on Bars, pubs, and restaurants
bars <- opq(bbox = c(xmin, ymin, xmax, ymax)) %>% 
  add_osm_feature(key = 'amenity', value = c("bar", "pub", "restaurant")) %>%
  osmdata_sf()

bars<-
  bars$osm_points%>%
  .[miami.base,]

bars<-
  bars%>%
  st_transform('ESRI:102658')
  
MiamiProperties<-
  MiamiProperties %>%
  mutate(
    bars_nn1= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),1),
    bars_nn2= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),2),
    bars_nn3= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),3),
    bars_nn4= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),4),
    bars_nn5= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(bars),5))

MiamiProperties$bars_Buffer =
  st_buffer(MiamiProperties, 660) %>%
  aggregate(mutate(dplyr::select(bars), counter = 1),., sum) %>%
  pull(counter)

MiamiProperties<-
  MiamiProperties%>%
  mutate(bars_Buffer = replace_na(bars_Buffer, 0))

## Add data on crime- Sexual Offenders and Predators within Miami-Dade County point data 
miami.sexualoffenders <-  
  st_read("https://opendata.arcgis.com/datasets/f8759d722aeb4198bfe7c4ad780604d2_0.geojson") %>%
  filter(CITY == "MIAMI" | CITY == "MIAMI BEACH" | CITY == "Miami" | CITY == "Miami Beach") %>%
  st_transform('ESRI:102658')

MiamiProperties$sexualoffenders_Buffer =
  st_buffer(MiamiProperties, 660) %>%
  aggregate(mutate(dplyr::select(miami.sexualoffenders), counter = 1),., sum) %>%
  pull(counter)

MiamiProperties<-
  MiamiProperties%>%
  mutate(sexualoffenders_Buffer = replace_na(sexualoffenders_Buffer, 0))

MiamiProperties <-
  MiamiProperties %>% 
  mutate(
    crime_nn1= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),1),
    crime_nn2= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),2),
    crime_nn3= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),3),
    crime_nn4= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),4),
    crime_nn5= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(miami.sexualoffenders),5))

## Add the data on Park Facilities
Parks<-st_read("https://opendata.arcgis.com/datasets/8c9528d3e1824db3b14ed53188a46291_0.geojson")%>%
st_transform('ESRI:102658')

MiamiProperties<-
  MiamiProperties %>% 
  mutate(
    parks_nn1= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),1),
    parks_nn2= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),2),
    parks_nn3= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),3),
    parks_nn4= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),4),
    parks_nn5= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(Parks),5))

MiamiProperties$parks.Buffer =
  st_buffer(MiamiProperties, 660) %>%
  aggregate(mutate(dplyr::select(Parks), counter = 1),., sum) %>%
  pull(counter)

MiamiProperties<-
  MiamiProperties%>%
  mutate(parks.Buffer = replace_na(parks.Buffer, 0))

#TOD or non-TOD; distance to transit stop?
metrorail_stop<-st_read("https://opendata.arcgis.com/datasets/ee3e2c45427e4c85b751d8ad57dd7b16_0.geojson")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(NAME)

metromover_stop<-st_read("https://opendata.arcgis.com/datasets/aec76104165c4e879b9b0203fa436dab_0.geojson")%>%
  st_transform('ESRI:102658')%>%
  dplyr::select(NAME)

metro_stops<-
  rbind(metromover_stop,metrorail_stop)

#Distance to metro_stop (Added a column for the distance to the nearest stop and a column for homes that are within 0.5 miles of a stop)
MiamiProperties<-
  MiamiProperties %>% 
  mutate(
    metro_nn1= nn_function(st_coordinates(st_centroid(MiamiProperties)),st_coordinates(metro_stops),1),
    Halfmile_metro=ifelse(metro_nn1<2640,"Halfmile_metro","Non_Halfmile_metro"))
                                                      
```

**Adding Neighborhood and Elementary School Names to Each Home**

```{r Neighborhood, message=FALSE, warning=FALSE, results='hide'}
#Add Elementary School Name to Each Property
elementary.school.clean<-
  elementary.school.boundaries%>%
  dplyr::select(NAME)%>%
  rename(elem_name=NAME)

MiamiProperties<-
  MiamiProperties%>%
  st_join(elementary.school.clean)

#Add neighborhood name to each property
MiamiProperties<-
  MiamiProperties%>%
  st_join(all_nhoods_MB)#updated to include more designations in MB (note these are numbers not names)

#Add variable for Miami or Miami Beach
MiamiProperties<-
  MiamiProperties%>%
  mutate(MiamiBeach=ifelse(Property.City=="Miami Beach","Yes","No"))
```

**Loading Census Data**

```{r Census data,message=FALSE, warning=FALSE, cache=TRUE, results='hide'}
## Load in census data
census_api_key("41e1c0d912341017fa6f36a5da061d3b23de335e", overwrite = TRUE)

selected_vars <- c("B02001_001E", # Estimate!!Total population by race -- ##let's double check that it's okay to use this as long as we justify it
                   "B02001_002E", # People describing themselves as "white alone"
                   "B02001_003E", # People describing themselves as "black" or "african-american" alone
                   "B15001_050E", # Females with bachelors degrees
                   "B15001_009E", # Males with bachelors degrees
                   "B19013_001E", # Median HH income
                   "B25058_001E", # Median rent
                   "B06012_002E", # Total poverty
                   "B08301_001E", # People who have means of transportation to work
                   "B08301_002E", # Total people who commute by car, truck, or van
                   "B08301_010E", # Total people who commute by public transportation"
                   "B03002_012E", # Estimate Total Hispanic or Latino by race
                   "B19326_001E", # Median income in past 12 months (inflation-adjusted)
                   "B07013_001E", # Total households
                   "B07013_002E", # Total owner-occupied households
                   "B07013_003E", # total renter-occupied households
                   "B25027_001E",
                   "B25027_010E",
                   "B25038_002E",
                   "B25038_003E",
                   "B25038_004E",
                   "B25038_005E",
                   "B19001_017E")

tracts18 <- 
  get_acs(geography = "tract", 
          variables = selected_vars, 
          year=2018, 
          state=12,
          county = 086,
          geometry=T, 
          output="wide") %>%
  st_transform('ESRI:102658') %>%
  rename(TotalPop = B02001_001E, 
         Whites = B02001_002E,
         Blacks = B02001_003E,
         FemaleBachelors = B15001_050E, 
         MaleBachelors = B15001_009E,
         MedHHInc = B19013_001E, 
         MedRent = B25058_001E,
         TotalPoverty = B06012_002E,
         TotalCommute = B08301_001E,
         CarCommute = B08301_002E,
         PubCommute = B08301_010E,
         TotalHispanic = B03002_012E,
         MedInc = B19326_001E,
         TotalHH = B07013_001E,
         OwnerHH = B07013_002E,
         RenterHH = B07013_003E,
         #TotalHH2 = B25027_001E,
         HHNoMort = B25027_010E,
         Own2017later = B25038_003E,
         Own201516 = B25038_004E,
         Own201014 = B25038_005E,
         HH200k = B19001_017E) %>%
  dplyr::select(-NAME, -starts_with("B0"), -starts_with("B1"), -starts_with("B2")) %>%
  mutate(pctWhite = (ifelse(TotalPop > 0, Whites / TotalPop,0))*100,
         pctBlack = (ifelse(TotalPop > 0, Blacks / TotalPop,0))*100,
         pctHis = (ifelse(TotalPop >0, TotalHispanic/TotalPop,0))*100,
         pctBlackorHis = (ifelse (TotalPop>0, (Blacks+TotalHispanic)/TotalPop,0)) *100,
         pctBachelors = (ifelse(TotalPop > 0, ((FemaleBachelors + MaleBachelors) / TotalPop),0)) *100,
         pctPoverty = (ifelse(TotalPop > 0, TotalPoverty / TotalPop, 0))*100,
         pctCarCommute = (ifelse(TotalCommute > 0, CarCommute / TotalCommute,0))*100,
         pctPubCommute = (ifelse(TotalCommute > 0, PubCommute / TotalCommute,0))*100,
         pctOwnerHH = (ifelse(TotalHH > 0, OwnerHH / TotalHH,0))*100,
         pctRenterHH = (ifelse(TotalHH > 0, RenterHH / TotalHH,0))*100,
         pctNoMortgage = (ifelse(TotalHH > 0, HHNoMort / TotalHH,0))*100,
         pctOwnerSince2010 = (ifelse(OwnerHH > 0, ((Own2017later + Own201516 + Own201014) / OwnerHH),0)) *100,
         pctHH200kOrMore = (ifelse(TotalHH > 0, (HH200k/ TotalHH),0))*100,
         year = "2018") %>%
  mutate(MedHHInc = replace_na(MedHHInc, 0),
         MedRent = replace_na(MedRent,0)) %>%
  dplyr::select(-Whites, -Blacks, -FemaleBachelors, -MaleBachelors, -TotalPoverty, -CarCommute, -PubCommute, -TotalCommute, -TotalHispanic)

#merge the data into the MiamiProperties dataframe
MiamiProperties <-st_join(MiamiProperties,tracts18)
```

**Completing Feature Engineering and Filtering Out Homes Where Sales Prices Have Been Removed**

```{r remove toPredict, message=FALSE, warning=FALSE, results='hide'}
MiamiPropertiesAll<-MiamiProperties

#filter out the houses that we will need to predict
MiamiProperties<-
  MiamiProperties%>%
  filter(toPredict == 0)
```

### Variables
Present a table of summary statistics with variable descriptions. Sort these variables by their category (internal characteristics, amenities/public services or spatial structure). Check out the `stargazer` package for this.


## Correlation

```{r}
engin_vars_table <-data.frame(
  Variable = c("CoastDist", "milecoast", "bars_nn1 ~ 5", "bars_Buffer", "crime_nn1 ~ 5","sexualoffenders_Buffer", "park_nn1 ~ 5", "parks.Buffer" , "metro_nn1", "Halfmile_metro","pctWhite", "pctBlack", "pctHis", "pctBlackorHis", "pctBachelors","pctPoverty", "pctCarCommute", "pctPubCommute", "pctOwnerHH", "pctRenterHH", "pctNoMortgage", "pctOwnerSince2010", "pctHH200kOrMore", "pool", "singlefamily", "estates", "dock", "Age", "luxury", "elevator", "BeachView"),
  Dataset = c("OpenStreetMap", "OpenStreetMap", "OpenStreetMap", "OpenStreetMap", "Miami-Dade County Open Data Hub", "Miami-Dade County Open Data Hub", "Miami-Dade County Open Data Hub", "Miami-Dade County Open Data Hub", "Miami-Dade County Open Data Hub", "Miami-Dade County Open Data Hub", "Miami-Dade County Open Data Hub", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "U.S. Census Bureau", "Provide Miami Housing Data", "Provide Miami Housing Data", "Provide Miami Housing Data", "Provide Miami Housing Data", "Provide Miami Housing Data", "Provide Miami Housing Data", "Provide Miami Housing Data", "Provide Miami Housing Data"),
  Description = c("Distance to coast", "Units within a mile from the coast", "Average distances of 1-5 bars", "Number of bars within half mile from a housing units", "Average distances of 1-5 registered sexual offenders", "Number of sexual offenders within half mile from a housing unit", "Average distances of 1-5 parks", "Number of parks within half mile from the unit", "Distance to closest metrorail station", "Units within half mile from a metrorail stations", "Percentage of White population", "Percentage of Black population", "Percentage of Hispanic populaiton", "Percentage of Black and Hispanic population", "Percentage of population with at least Bachelor's degree", "Percentage of population below the poverty line", "Percentage of population communiting by car", "Percentage of population commuting by public transit", "Percentage of households in owner-occupied units", "Percentage of households in renter-occupied units", "Percentage of households with no mortgage", "Percentage of households who owned the house since 2010 or later", "Percentage of households with income of $200K or more", "Units with a pool", "Single Family zoning units", "Estates Zoning Units", "Units with a dock", "Age of the units", "Units with luxuary amenitiss", "Units with an elevator", "Units with a beach view"),
  "Data type" = c("continuous", "categorical", "continuous", "continuous", "continuous", "continuous", "continuous", "continuous", "continuous", "categorical", "continuous", "continuous", "continuous", "continuous", "continuous", "continuous", "continuous","continuous", "continuous", "continuous", "continuous", "continuous", "continous", "categorical", "categorical", "categorical", "categorical", "continous", "categorical", "categorical", "categorical"),
  "Final model" = c("No", "No", "No", "No", "No", "Yes", "Yes", "No", "No", "Yes", "No", "No", "Yes", "No", "Yes", "No", "Yes", "No", "Yes", "No", "No", "No", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "No")
)

kbl(engin_vars_table) %>%
  kable_paper(c("striped", "hover"), html_font = "Montserrat", full_width = F) %>%
  kable_material() %>%
  kable_styling (bootstrap_options = "striped", "condensed", font_size = 11) %>%
  row_spec(0, bold = T, color = "white", background = "dodgerblue", font_size = 13)%>%
  column_spec(1, bold = T) %>%
  column_spec(2, width = "25%") %>%
  column_spec(3, width = "40%")
```

## Correlation:
As part of the exploratory analysis, we examined correlation to assist in identifying features that may be useful for predicting sales price. A correlation matrix helps us visualize correlation across numeric variables. In the figures, the darker colors imply stronger correlation. These plot helps to determine features that are correlated to sale prices (see sale prices row) and variables that are correlated with each other. Figure 1 depicts a correlation plot of variables derived from the U.S. Census Bureau. Figure 2 depicts the correlation between the numeric features included in the final model. We developed several correlation matrices with additional variables in order to help determine features to include in the final model.

```{r Correlation Matrix, message=FALSE, warning=FALSE}
#Correlation of Census Variables
censusVars <- 
  select(st_drop_geometry(MiamiProperties), SalePrice, MedHHInc, MedRent, pctWhite, pctBlack, pctHis, pctBlackorHis, 
          pctBachelors, pctPoverty, pctCarCommute, pctPubCommute, pctOwnerHH, pctRenterHH) %>% na.omit()
ggcorrplot(
  round(cor(censusVars), 1), 
  p.mat = cor_pmat(censusVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
  labs(title = "Correlation Across Census Variables",
       caption="Figure 1. Correlation Plot of Census Variables") 


#Correlation of Variables Included in Model
reg_final_vars <- 
  select(st_drop_geometry(MiamiProperties), SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, parks_nn1, MedHHInc, pctHis, pctBachelors, pool, 
                            singlefamily, pctOwnerHH, pctCarCommute, pctHH200kOrMore, Halfmile_metro, luxury, elevator, dock,
         sexualoffenders_Buffer, estates) %>% na.omit()

ggcorrplot(
  round(cor(reg_final_vars), 1), 
  p.mat = cor_pmat(reg_final_vars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
  labs(title = "Correlation Across Final Numeric Features",
       caption="Figure 2. Correlation Plot of All Numeric Features Included in Final Model") 
```

The charts below plot sales price as a function of numeric features. Figure 3 is an example of a diagnostic tool used to select features for inclusion in the final model. The series of plots show the relationship between sale price and 6 crime variables for sexual offender and predators within the region (5 nearest neighbor variables and one buffer variable that counts the number of offenses within 1/8 mile of each home). By reviewing the slopes of the plotted lines, we selected the crime variable that was most highly correlated with Sale Prices to include in the final model. 

Figure 4 depicts four correlation scatterplots between continuous features and sale prices that suggest correlation. In all cases, the regression line slopes upward from left to right, meaning that on average, as the variable of interest (e.g., home size, median household income, distance to the nearest park, and household income greater than $200,000) increases, so does price. Correlation can also be described by the slope of the line. The greater the slope, the greater the feature's effect on price.

```{r Correlation scatterplots, message=FALSE, warning=FALSE}
#Correlation Scatterplots for all NN variable for Crime, as an example:
st_drop_geometry(MiamiProperties) %>% 
  dplyr::select(SalePrice, crime_nn1, crime_nn2, crime_nn3, crime_nn4, crime_nn5, sexualoffenders_Buffer) %>%
  gather(Variable, Value, -SalePrice) %>% 
  ggplot(aes(Value, SalePrice)) +
  geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
  facet_wrap(~Variable, ncol = 3, scales = "free") +
  labs(title = "Correlation between Sale Price and Crime Features",
       caption="Figure 3. Correlation Scatterplot Depicting the Relationship Between Sale Price and Crime Features") +
  plotTheme()+
  theme(strip.text.x = element_text(size = 10))


#Correlation Scatterplots for Variables of Interest
st_drop_geometry(MiamiProperties) %>% 
  mutate(Age = 2020 - EffectiveYearBuilt) %>%
  dplyr::select(SalePrice, LivingSqFt, parks_nn1, MedHHInc, pctHH200kOrMore) %>%
  #filter(SalePrice <= 1000000, Age < 500) %>%
  gather(Variable, Value, -SalePrice) %>% 
  ggplot(aes(Value, SalePrice)) +
  geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
  facet_wrap(~Variable, ncol = 3, scales = "free") +
  labs(title = "Price as a Function of Continuous Variables",
       caption="Figure 4. Correlation between Selected Continuous Variables and Sale Price") +
  plotTheme()+
  theme(strip.text.x = element_text(size = 10))
```

Some of the features included in the analysis are categorical rather than numeric (see Figure 5). Instead of using slope to calculate correlation, we evaluate the difference in mean price across each category. Differences in mean sales prices across categories suggest that the variable may be a good predictor of Sale Prices. 

```{r Categorical variable charts, message=FALSE, warning=FALSE}
st_drop_geometry(MiamiProperties) %>%
  dplyr::select(SalePrice, pool, elevator, dock)%>%
  gather(Variable,Value, -SalePrice)%>%
  ggplot(aes(Value, SalePrice))+
  geom_bar(position="dodge",stat="summary", fun.y="mean")+
  facet_wrap(~Variable, ncol=1, scales="free")+
  labs(title = "Price as a Function of Categorical Variables",
       caption="Figure 5. Correlation between Selected Categorical Variables and Average Sale Price") +
  plotTheme()
```

Figure 6 depicts the spatial distribution of sale prices (or price per square foot) across Miami and Miami Beach. The map suggests that prices are clustered within the city, rather than randomly distributed. In other words, homes with a greater price per square foot (orange color) are grouped together (e.g., on the eastern coast of the mainland and within Miami Beach) and homes with a lower price per square foot (green color) are grouped together father inland.

```{r Sale price map, message=FALSE, warning=FALSE}
Miami.Plot<-
  MiamiProperties%>%
  mutate(PricePerSq=SalePrice/ActualSqFt)

ggplot()+
  geom_sf(data=all_nhoods_MB, fill="grey40")+
  geom_sf(data=Miami.Plot, aes(colour=q5(PricePerSq)),
          show.legend="point", size=.75)+
  scale_colour_manual(values=palette5,
                      labels=qBr(Miami.Plot, "PricePerSq"),
                      name="Quintile\nBreaks")+
  labs(title="Price Per Square Foot, Miami",
       caption="Figure 6. Price per Square Foot for Homes in Miami and Miami Beach") +
  mapTheme()
```

The maps below depict independent variables included in the final model. Figure 7 depicts the density of sexual offenders and predators in Miami and Miami Beach. The locations with the greatest density of sexual offenders and predators in the norther portions of Miami. Figure 8 shows the locations of County

```{r independent variable maps, message=FALSE, warning=FALSE}
#density of sexual offenders
sexual_offend_map<-
  miami.sexualoffenders%>%
  st_intersection(all_nhoods)

ggplot() + geom_sf(data = all_nhoods_MB, fill = "grey40") +
  stat_density2d(data = data.frame(st_coordinates(sexual_offend_map)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "#25CB10", high = "#FA7800", name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Locations of Sexual Offenders and Predators",
       caption="Figure 7. Density of Sexual Offenders in Miami and Miami Beach") +
  mapTheme()


#Parks
Parks_map<-
  Parks%>%
  st_intersection(all_nhoods_MB)
ggplot()+
  geom_sf(data=all_nhoods_MB, fill="grey40")+
  geom_sf(data=Parks_map, size=1, color="lightgreen")+
  labs(title="Park Locations",
       catption="Figure 8. Locations of Park Facilities in Miami and Miami Beach") +
  mapTheme()


#Single Family Homes vs. Multi Family Homes
ggplot()+
  geom_sf(data=all_nhoods_MB, fill="grey40")+
  geom_sf(data=Miami.Plot, aes(colour=singlefamily),
          show.legend="point", size=.75)+
  labs(title="Single vs. Multi Family Homes",
       caption="Figure 9. Single and Multi Family Homes in Miami and Miami Beach") +
  mapTheme()

```

# 3. Methods

  - Gathering Data (brief description, code is provided in section above)
  - Creating Features (brief description, code is provided in section above)
  - Testing for correlation (brief description, code is provided in section above)
  - Building Models (brief description & code)
        - one example model
        - provide written interpretation
        - trimmed/altered from the initial model
        - stepwise function process
        - final model (describe why we added a few more vars that we created)
        - add stargazer table with all regs models to compare
  - Cross Validating (describe, code shown in results below?)

## Model Building

# 4. Model Building
After exploring and testing correlations of all the variables, we have started our
```{r Models, message=FALSE, warning=FALSE}
## model with physical attributes of the housing
reg1 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
                  dplyr::select(SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, elevator, dock, BeachView, pool, luxury, singlefamily, estates))

## add addtional engineered variables
reg2 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
                  dplyr::select(SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, 
                                parks_nn1, MedRent, MedHHInc, pctBlackorHis, pctBachelors, pool, 
                                pctOwnerHH, crime_nn5, milecoast, pctNoMortgage, pctOwnerSince2010, pctCarCommute, pctPubCommute, 
                                pctPoverty, Halfmile_metro, CoastDist, pctHH200kOrMore, elevator, dock, luxuary, BeachView))

## include almost all variables
reg3 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
                  dplyr::select(SalePrice, LotSize, Bed, Bath, Age, 
                                ActualSqFt, parks_nn1, MedRent, MedHHInc, pctWhite, pctBlack, pctHis, pctBlackorHis, pctBachelors, pool, 
                                singlefamily, pctOwnerHH, pctRenterHH, crime_nn5, milecoast, pctNoMortgage, pctOwnerSince2010, pctCarCommute, 
                                pctPubCommute, pctPoverty, Halfmile_metro, metro_nn1, sexualoffenders_Buffer, milecoast, CoastDist, pctHH200kOrMore))
summary(reg1)
## trimmed/ cleaned up model from the inital model
#singlefamily, pctOwnerHH, pctRenterHH, crime_nn5, milecoast, pctNoMortgage, pctOwnerSince2010, pctCarCommute, pctPubCommute, pctPoverty, Halfmile_metro, metro_nn1, sexualoffenders_Buffer, milecoast, CoastDist, pctHH200kOrMore, luxury, elevator, dock, BeachView, estates)


##stepwise backward function
step( lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
           dplyr::select(SalePrice, LotSize, Bed, Bath, Age, 
                         ActualSqFt, parks_nn1, MedRent, MedHHInc, pctWhite, pctBlack, pctHis, pctBlackorHis, pctBachelors, pool, 
                         singlefamily, pctOwnerHH, pctRenterHH, crime_nn5, milecoast, pctNoMortgage, pctOwnerSince2010, pctCarCommute, pctPubCommute, 
                         pctPoverty, Halfmile_metro, metro_nn1, sexualoffenders_Buffer, milecoast, CoastDist,pctHH200kOrMore, luxury, elevator, dock, estates)), direction="backward")
##output
reg4 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
                           dplyr::select(SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, parks_nn1, MedRent, MedHHInc, pctWhite, pctBlack, pctHis , pctBachelors, pool, singlefamily, pctOwnerHH, 
                                         pctNoMortgage,  pctCarCommute, pctHH200kOrMore , luxury, elevator, dock , estates))

# add crim_nn5 to reg5
reg5 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
                    dplyr::select(SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, parks_nn1, MedRent, MedHHInc, pctBlackorHis, pctBachelors, pool, 
                                  singlefamily, pctOwnerHH, pctCarCommute, pctHH200kOrMore, Halfmile_metro, luxury, elevator, dock, crime_nn5, BeachView, estates))
summary(reg4)
#add crime buffer to reg5
reg6 <- lm(SalePrice ~ ., data = st_drop_geometry(MiamiProperties) %>% 
             dplyr::select(SalePrice, LotSize, Bed, Bath, Age, ActualSqFt, parks_nn1, MedHHInc, pctHis, pctBachelors, pool, 
                            singlefamily, pctOwnerHH, pctCarCommute, pctHH200kOrMore, Halfmile_metro, luxury, elevator, dock, sexualoffenders_Buffer, estates))
```
```{r, echo = TRUE, warning = FALSE, results = "asis"}
stargazer(reg1, reg2, reg3, reg4, reg5, reg6, type = "html")
```

## Cross Validation

# 6. Predicitons
